{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Random Forest on CICIDS2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import time\n",
    "\n",
    "from numpy import array\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import completeness_score, homogeneity_score, v_measure_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to where ML files are stored\n",
    "path = '../dataset/CICIDS2017'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "# concatenate the 8 files into 1\n",
    "dataset = pd.concat((pd.read_csv(f) for f in all_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Peak at first 5 records in the dataset\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# get statistics about each feature\n",
    "dataset.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# check all the values are numerical\n",
    "# if not, would have to encode\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data\n",
    "\n",
    "Remove NaN/Null/Inf Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "dataset.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Replace Inf values with NaN\n",
    "dataset = dataset.replace([np.inf, -np.inf], np.nan)\n",
    "# Drop all occurences of NaN\n",
    "dataset = dataset.dropna()\n",
    "# Double check these are all gone\n",
    "dataset.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename Label columns\n",
    "dataset = dataset.rename(columns={' Label': 'Label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "dataset = dataset.replace(['Heartbleed', 'Web Attack � Sql Injection', 'Infiltration'], np.nan)\n",
    "dataset = dataset.dropna()\n",
    "dataset['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[dataset.Label == 'Web Attack � Brute Force', ['Label']] = 'Brute Force'\n",
    "dataset.loc[dataset.Label == 'Web Attack � XSS', ['Label']] = 'XSS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Create attack column, containing binary labels\n",
    "dataset['Attack'] = np.where(dataset['Label'] == 'BENIGN', 0, 1)\n",
    "dataset['Attack'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Proposed Groupings\n",
    "attack_group = {'BENIGN': 'benign', \n",
    "                'DoS Hulk': 'dos',\n",
    "                'PortScan': 'probe', \n",
    "                'DDoS': 'ddos',\n",
    "                'DoS GoldenEye': 'dos', \n",
    "                'FTP-Patator': 'brute_force',\n",
    "                'SSH-Patator': 'brute_force', \n",
    "                'DoS slowloris': 'dos', \n",
    "                'DoS Slowhttptest': 'dos',\n",
    "                'Bot': 'botnet',\n",
    "                'Brute Force': 'web_attack', \n",
    "                'XSS': 'web_attack'}\n",
    "# Create grouped label column\n",
    "dataset['Label_Category'] = dataset['Label'].map(lambda x: attack_group[x])\n",
    "dataset['Label_Category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data\n",
    "\n",
    "Split data using 60:20:20 ratio, for training, test and validation dataset. We stratified so that the attack rate remained the same across all 3 sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Different labeling options\n",
    "attacks = ['Label', 'Label_Category', 'Attack']\n",
    "\n",
    "# xs=feature vectors, ys=labels\n",
    "xs = dataset.drop(attacks, axis=1)\n",
    "ys = dataset[attacks]\n",
    "\n",
    "# split dataset - stratified\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(xs, ys, test_size=0.4, random_state=0, stratify=ys['Label'])\n",
    "x_test, x_validate, y_test, y_validate = train_test_split(x_temp, y_temp, test_size=0.5, random_state=0, stratify=y_temp['Label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "column_names = np.array(list(x_train))\n",
    "to_drop = []\n",
    "for x in column_names:\n",
    "    size = x_train.groupby([x]).size()\n",
    "    # check for columns that only take one value\n",
    "    if (len(size.unique()) == 1):\n",
    "        to_drop.append(x)\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop these because they only contain one value, and so are redundant as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop(to_drop, axis=1)\n",
    "x_validate = x_validate.drop(to_drop, axis=1)\n",
    "x_test = x_test.drop(to_drop, axis=1)\n",
    "dataset_copy = dataset.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Normalization\n",
    "\n",
    "Using minmax normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Normalise\n",
    "min_max_scaler = MinMaxScaler().fit(x_train)\n",
    "\n",
    "# Apply normalization to dataset\n",
    "x_train = min_max_scaler.transform(x_train)\n",
    "x_validate = min_max_scaler.transform(x_validate)\n",
    "x_test = min_max_scaler.transform(x_test)\n",
    "\n",
    "# All values between 0 and 1\n",
    "pd.Series(x_train.flatten()).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Use chi2 select k best First, score all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = SelectKBest(score_func=chi2, k=x_train.shape[1])\n",
    "\n",
    "#fit features to the training dataset\n",
    "fit = features.fit(x_train, y_train.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# plot the score associated with each feature\n",
    "features_df = pd.DataFrame({\n",
    "    'feature': dataset_copy.columns,\n",
    "    'score': features.scores_\n",
    "})\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(features_df)), features_df['score'])\n",
    "plt.xticks(range(len(features_df)), features_df['feature'], rotation=90, fontsize=5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('features.png', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the features by importance score\n",
    "features_df = features_df.sort_values('score', ascending=False)\n",
    "sorted_importances = features_df['score'].values\n",
    "sorted_features = features_df['feature'].values\n",
    "\n",
    "x_values = range(len(sorted_importances))\n",
    "\n",
    "# plot the cumulative scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "cumulative_importances = np.cumsum(sorted_importances)\n",
    "plt.plot(x_values, cumulative_importances)\n",
    "\n",
    "# Draw line at 99% of importance retained \n",
    "value99 = cumulative_importances[-1]*0.99\n",
    "plt.hlines(y=value99, xmin=0, xmax=len(sorted_importances), color='r', linestyles='dashed')\n",
    "plt.xticks(x_values, sorted_features, rotation='vertical', fontsize=5)\n",
    "plt.yticks([], [])\n",
    "plt.xlabel('Feature Variable', fontsize=8)\n",
    "plt.title('A Chart to Show Cumulative Feature Scores', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig('cum_features.png', dpi=300)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
